name: abs-core

networks:
  abs-net:
    name: ${ABS_NETWORK}
    driver: bridge

volumes:
  ollama_models:
  qdrant_storage:
  redis_data:
  postgres_data:

services:

  # ---- LLM Runtime (choose ONE) ----
  # A) OLLAMA (default): simple, offline, great for workstation
  ollama:
    #image: ollama/ollama:0.3.8
    image: ollama/ollama:latest
    container_name: abs-ollama
    restart: unless-stopped
    runtime: nvidia
    environment:
      TZ: ${TZ}
      OLLAMA_KEEP_ALIVE: "24h"
    volumes:
      - ollama_models:/root/.ollama
    ports:
      - "${OLLAMA_PORT}:11434"
    networks: [abs-net]
    healthcheck:
      test: ["CMD", "wget", "-q", "-O", "-", "http://localhost:11434/api/tags"]
      interval: 10s
      timeout: 3s
      retries: 30
    # If you plan to use vLLM instead, comment this service out and enable vllm below.

  # B) vLLM (OpenAI-compatible). Use instead of Ollama if you want /v1/chat/completions API.
  # vllm:
  #   image: vllm/vllm-openai:0.5.4
  #   container_name: abs-vllm
  #   restart: unless-stopped
  #   runtime: nvidia
  #   environment:
  #     TZ: ${TZ}
  #   command: >
  #     --model ${VLLM_MODEL}
  #     --gpu-memory-utilization 0.90
  #     --dtype float16
  #     --max-model-len 8192
  #   ports:
  #     - "${VLLM_PORT}:8000"
  #   networks: [abs-net]
  #   healthcheck:
  #     test: ["CMD", "wget", "-q", "-O", "-", "http://localhost:8000/v1/models"]
  #     interval: 10s
  #     timeout: 3s
  #     retries: 40

  # ---- Vector DB ----
  qdrant:
    image: qdrant/qdrant:v1.9.2
    container_name: abs-qdrant
    restart: unless-stopped
    environment:
      TZ: ${TZ}
    volumes:
      - qdrant_storage:/qdrant/storage
    ports:
      - "6333:6333"   # REST
      - "6334:6334"   # gRPC
    networks: [abs-net]
    healthcheck:
      test: ["CMD", "wget", "-q", "-O", "-", "http://localhost:6333/collections"]
      interval: 10s
      timeout: 3s
      retries: 20

  # ---- Cache / Queue ----
  redis:
    image: redis:7.2
    container_name: abs-redis
    restart: unless-stopped
    command: ["redis-server", "--appendonly", "yes"]
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks: [abs-net]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 2s
      retries: 15

  # ---- Hub Gateway ----
  hub-gateway:
    build: ./gateway
    container_name: abs-hub-gateway
    environment:
      REDIS_URL: redis://redis:6379/0
      OLLAMA_BASE_URL: http://ollama:11434
      OPENAI_BASE_URL: http://vllm:8000/v1
      OPENAI_API_KEY: abs-local
      REGISTRY_PATH: /app/registry.json
      CATALOG_PATH: /app/catalog.json
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./gateway/catalog.json:/app/catalog.json
      - ./gateway/registry.json:/app/registry.json
    ports: ["8081:8081"]
    depends_on: [redis, postgresql]
    networks: [abs-net]

  # ---- Database ----
  postgresql:
    image: postgres:15
    container_name: document-hub-postgres
    restart: unless-stopped
    environment:
      TZ: ${TZ}
      POSTGRES_DB: document_hub
      POSTGRES_USER: hub_user
      POSTGRES_PASSWORD: secure_password
      POSTGRES_INITDB_ARGS: --encoding=UTF-8 --lc-collate=C --lc-ctype=C
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./gateway/postgres-init:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    networks: [abs-net]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U hub_user -d document_hub"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - "abs.service=postgresql"
      - "abs.managed-by=gateway"
      - "abs.environment=production"
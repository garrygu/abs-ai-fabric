# CES Staff Demo Guide

**Best Practices for Introducing ABS AI Products**

---

## The 30-Second Pitch

> "This is an ABS Workstation running AI entirely locallyâ€”no cloud, no subscriptions, complete privacy. Watch this GPU ring? That's real AI inference happening right now. Everything you seeâ€”the chat, the document analysis, the visualizationsâ€”runs on this single machine."

---

## Demo Flow (Recommended Order)

### 1ï¸âƒ£ **Catch Attention** (Attract Mode)
Let the Workstation Console's Attract Mode draw visitors in:
- Particle effects and GPU visualization run automatically
- Don't interruptâ€”let it work its magic
- When someone approaches, touch the screen to exit

### 2ï¸âƒ£ **Show the Power** (Performance Screen)
- Point to the GPU utilization ring
- "See that 47%? That's real AI running right now"
- Highlight the real-time metrics

### 3ï¸âƒ£ **Demonstrate AI** (Live Demo)
- Run a quick chat or document analysis
- Show the response generating in real-time
- Emphasize: "All happening locally"

### 4ï¸âƒ£ **Explain the Platform** (AI Fabric)
- Show the admin interface
- "One platform to manage all AI workloads"
- Point out the installed models

### 5ï¸âƒ£ **Close** (Call to Action)
- Offer spec sheet or QR code
- "Want to see it run your workload?"

---

## Focus Areas by Audience

### ğŸ¢ **Enterprise IT / Tech Leads**
**Focus on:** Security, privacy, integration
- "All data stays on-premises"
- "OpenAI-compatible APIâ€”drop-in replacement"
- "Manage models centrally through one interface"
- "No per-token costs"

### ğŸ’¼ **Business Decision Makers**
**Focus on:** ROI, competitive advantage
- "AI capabilities without cloud dependency"
- "Fixed hardware cost vs. ongoing cloud fees"
- "Deploy AI without compliance concerns"
- "Same models the big players use"

### ğŸ”§ **Developers / Technical Staff**
**Focus on:** Capabilities, extensibility
- "Run 70B parameter models locally"
- "Standard REST API integration"
- "Add your own applications easily"
- "Vector database included for RAG"

### ğŸ® **General Attendees**
**Focus on:** The wow factor
- "This is real AI, not a cloud demo"
- "Watch the GPU working in real-time"
- "Touch the screen to interact"

---

## Key Talking Points

### On Privacy & Security
- âœ… "Zero data leaves this machine"
- âœ… "No cloud calls, no API keys exposed"
- âœ… "Perfect for regulated industries"
- âœ… "Your data, your hardware, your control"

### On Performance
- âœ… "Real-time inference on local GPU"
- âœ… "Sub-second response times"
- âœ… "Run multiple models simultaneously"
- âœ… "No internet latency"

### On Cost
- âœ… "No per-token API fees"
- âœ… "One-time hardware investment"
- âœ… "ROI in months, not years"
- âœ… "Scale with hardware, not subscriptions"

### On Capability
- âœ… "Same models as ChatGPT and Claude"
- âœ… "Document analysis with citations"
- âœ… "Semantic search across documents"
- âœ… "Custom application support"

---

## What NOT to Do

âŒ **Don't get too technical** â€” Save deep dives for interested parties

âŒ **Don't block the screen** â€” Let people see the visuals

âŒ **Don't interrupt Attract Mode** â€” It's designed to draw people in

âŒ **Don't make promises about specs** â€” Refer to official materials

âŒ **Don't compare directly to competitors** â€” Focus on our strengths

---

## Common Questions & Answers

**Q: "Is this just running ChatGPT?"**
> No, this runs open-source models like Llama 3 and DeepSeek entirely locally. No cloud connection at all.

**Q: "How much does it cost?"**
> It's part of the ABS Workstation. No recurring subscription fees for the AI software.

**Q: "What models can it run?"**
> Any Ollama-compatible modelâ€”Llama 3, Mistral, DeepSeek, CodeLlama, and many more. The GPU VRAM determines the max model size.

**Q: "Can we train our own models?"**
> This platform is optimized for inference. Training typically requires different hardware, but fine-tuned models can be deployed here.

**Q: "Does it need internet?"**
> No. Once set up, it works completely offline.

**Q: "How hard is it to set up?"**
> Pre-configured on ABS Workstations. Turn it on and it's ready.

---

## Demo Scripts

### Quick Demo (2 minutes)
1. "This is an ABS Workstation with AI Fabric"
2. Point to GPU ring: "Real AI inference happening now"
3. Open chat, ask a question, watch response generate
4. "All local. No cloud. Complete privacy."

### Full Demo (5 minutes)
1. Start at Performance screenâ€”explain metrics
2. Navigate to Modelsâ€”show installed LLMs
3. Open Contract Reviewerâ€”upload a document
4. Show AI analysis with citations
5. Return to Attract Modeâ€”let visuals close the pitch

### Technical Deep Dive (10+ minutes)
1. Show AI Fabric admin interface
2. Explain service architecture
3. Demonstrate API calls
4. Discuss model loading/unloading
5. Talk about custom application integration

---

## Emergency Procedures

### If the demo freezes:
1. Refresh the browser (F5)
2. If still frozen, restart the app: close terminal, run `npm run dev`
3. Call for technical support

### If someone asks something you don't know:
1. "Great questionâ€”let me get our technical specialist"
2. Take their contact info for follow-up
3. Don't guess

### If Attract Mode won't start:
1. Wait 60 seconds of no interaction
2. Check that GPU metrics server is running
3. Ensure browser supports WebGPU (Chrome/Edge)

---

## Booth Etiquette

- ğŸ˜Š Smile and make eye contact
- ğŸ¤ Invite people to touch the screen
- ğŸ“± Have QR codes ready for more info
- ğŸ¯ Qualify interest level quickly
- â±ï¸ Respect their timeâ€”don't over-explain
- ğŸ“ Collect leads for follow-up
